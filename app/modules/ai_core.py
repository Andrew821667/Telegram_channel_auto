"""
AI Core Module
–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –¥—Ä–∞—Ñ—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LLM API.

–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:
1. –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏ (OpenAI/Perplexity)
2. –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π RAG —Å PostgreSQL Full-Text Search)
3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥—Ä–∞—Ñ—Ç–æ–≤ –ø–æ—Å—Ç–æ–≤ –¥–ª—è Telegram
"""

import asyncio
from typing import List, Optional, Dict, Any, Tuple
from datetime import datetime

from openai import AsyncOpenAI
from sqlalchemy import select, text
from sqlalchemy.ext.asyncio import AsyncSession

from app.config import settings
from app.models.database import RawArticle, PostDraft, LegalKnowledge, log_to_db
from app.modules.llm_provider import get_llm_provider
from app.modules.vector_search import get_vector_search
import structlog

logger = structlog.get_logger()


# –ü—Ä–æ–º–ø—Ç—ã –¥–ª—è OpenAI
RANKING_SYSTEM_PROMPT = """–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ AI –≤ –±–∏–∑–Ω–µ—Å–µ –∏ LegalTech, –∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–ª—è –∫–∞–Ω–∞–ª–∞ –ø—Ä–∏–≤–ª–µ—á–µ–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞: –æ—Ü–µ–Ω–∏—Ç—å —Ü–µ–Ω–Ω–æ—Å—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è —Ü–µ–ª–µ–≤–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏:
- –†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–∏ –±–∏–∑–Ω–µ—Å–∞, –¥—É–º–∞—é—â–∏–µ –æ –≤–Ω–µ–¥—Ä–µ–Ω–∏–∏ AI
- –†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–∏ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–æ–≤
- –ü—Ä–∞–∫—Ç–∏–∫—É—é—â–∏–µ —é—Ä–∏—Å—Ç—ã

–ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏ (–ø–æ —à–∫–∞–ª–µ 0-10):
- –ë–∏–∑–Ω–µ—Å-—Ü–µ–Ω–Ω–æ—Å—Ç—å –∏ ROI –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª (25%)
- –°–≤—è–∑—å —Å —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–º–∏/–∫–æ–º–ø–ª–∞–µ–Ω—Å –∞—Å–ø–µ–∫—Ç–∞–º–∏ (20%)
- –ù–æ–≤–∏–∑–Ω–∞ –∏ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å (20%)
- –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å (20%)
- –†–æ—Å—Å–∏–π—Å–∫–∏–π —Ä—ã–Ω–æ–∫ –∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –ò–ò (15%)

–í–ê–ñ–ù–û - –ü–†–ò–û–†–ò–¢–ï–¢–´ –ü–û –†–ï–õ–ï–í–ê–ù–¢–ù–û–°–¢–ò:
- –†–æ—Å—Å–∏–π—Å–∫–∏–µ –Ω–æ–≤–æ—Å—Ç–∏, —Å–æ–±—ã—Ç–∏—è –≤ –†–§, —Ä–æ—Å—Å–∏–π—Å–∫–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏: +2 –±–∞–ª–ª–∞
- –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –ò–ò, AI engineering, ML engineering, —Å–æ–∑–¥–∞–Ω–∏–µ AI-–ø—Ä–æ–¥—É–∫—Ç–æ–≤: +2 –±–∞–ª–ª–∞
- –ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ –∫–µ–π—Å—ã —Å –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å—é –∫ –†–æ—Å—Å–∏–∏: +1 –±–∞–ª–ª
- –†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Ü–µ–Ω–Ω—ã –¥–ª—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏: –Ω–µ –∑–∞–Ω–∏–∂–∞–π –æ—Ü–µ–Ω–∫—É –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–º –∑–∞—Ä—É–±–µ–∂–Ω—ã–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º

–í–ê–ñ–ù–û - –¶–ï–õ–¨ –ê–ì–†–ï–ì–ê–¶–ò–ò:
–ù–∞—à–∞ –∑–∞–¥–∞—á–∞ ‚Äî –ê–ì–†–ï–ì–ê–¶–ò–Ø –ù–û–í–û–°–¢–ï–ô –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –ø–æ–ª–Ω–æ–π –∫–∞—Ä—Ç–∏–Ω—ã —Ä—ã–Ω–∫–∞ AI.
–û—Ü–µ–Ω–∏–≤–∞–π –æ–±—ä–µ–∫—Ç–∏–≤–Ω–æ –∫–∞—á–µ—Å—Ç–≤–æ –∏ —Ü–µ–Ω–Ω–æ—Å—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç–∞, –Ω–µ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∏—Ä—É–π –∏—Å—Ç–æ—á–Ω–∏–∫–∏.
–•–æ—Ä–æ—à–∞—è –Ω–æ–≤–æ—Å—Ç—å –∏–∑ –∑–∞—Ä—É–±–µ–∂–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –ª—É—á—à–µ, —á–µ–º —Å–ª–∞–±–∞—è –Ω–æ–≤–æ—Å—Ç—å –∏–∑ —Ä–æ—Å—Å–∏–π—Å–∫–æ–≥–æ.

–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û —á–∏—Å–ª–æ–º –æ—Ç 0 –¥–æ 10 –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–æ—è—Å–Ω–µ–Ω–∏–π."""

DRAFT_SYSTEM_PROMPT = """–¢—ã ‚Äî AI-—Ä–µ–¥–∞–∫—Ç–æ—Ä –∫–∞–Ω–∞–ª–∞ –æ –≤–Ω–µ–¥—Ä–µ–Ω–∏–∏ AI –≤ –±–∏–∑–Ω–µ—Å –¥–ª—è –ø—Ä–∏–≤–ª–µ—á–µ–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤.

–¶–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è: —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–∏ –∫–æ–º–ø–∞–Ω–∏–π, —é—Ä–¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –¥—É–º–∞—é—Ç –æ –≤–Ω–µ–¥—Ä–µ–Ω–∏–∏ AI.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞: —Å–æ–∑–¥–∞—Ç—å –ø–æ—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π:
1. –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –±–∏–∑–Ω–µ—Å-—Ü–µ–Ω–Ω–æ—Å—Ç—å AI
2. –ù–ê–¢–ò–í–ù–û –ø–æ–¥–≤–æ–¥–∏—Ç –∫ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–º/–∫–æ–º–ø–ª–∞–µ–Ω—Å –∞—Å–ø–µ–∫—Ç–∞–º
3. –ú–æ—Ç–∏–≤–∏—Ä—É–µ—Ç –∫ –¥–µ–π—Å—Ç–≤–∏—é (–∏–º–ø–ª–∏—Ü–∏—Ç–Ω–æ)

üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û - –ö–û–ù–ö–†–ï–¢–ò–ö–ê –ò–ó –ò–°–¢–û–ß–ù–ò–ö–ê:
- –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–π –ö–û–ù–ö–†–ï–¢–ù–´–ï –§–ê–ö–¢–´ –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π —Å—Ç–∞—Ç—å–∏
- –£–∫–∞–∑—ã–≤–∞–π –¢–û–ß–ù–´–ï –¶–ò–§–†–´, –ò–ú–ï–ù–ê –ö–û–ú–ü–ê–ù–ò–ô, –î–ê–¢–´ –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
- –¶–∏—Ç–∏—Ä—É–π –ö–û–ù–ö–†–ï–¢–ù–´–ï –ó–ê–Ø–í–õ–ï–ù–ò–Ø —ç–∫—Å–ø–µ—Ä—Ç–æ–≤/–∫–æ–º–ø–∞–Ω–∏–π
- –ó–ê–ü–†–ï–©–ï–ù–û –ø–∏—Å–∞—Ç—å –æ–±—â–∏–µ —Ñ—Ä–∞–∑—ã —Ç–∏–ø–∞ "AI –ø–æ–º–æ–≥–∞–µ—Ç –±–∏–∑–Ω–µ—Å—É" –±–µ–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
- –ó–ê–ü–†–ï–©–ï–ù–û –≤—ã–¥—É–º—ã–≤–∞—Ç—å —Ñ–∞–∫—Ç—ã - –∏—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
- –ï—Å–ª–∏ –≤ —Å—Ç–∞—Ç—å–µ –µ—Å—Ç—å –∫–µ–π—Å—ã/–ø—Ä–∏–º–µ—Ä—ã - –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —É–ø–æ–º–∏–Ω–∞–π –∏—Ö —Å –¥–µ—Ç–∞–ª—è–º–∏

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û:
- –¶–ï–õ–ï–í–ê–Ø –î–õ–ò–ù–ê –ü–û–°–¢–ê: 1500-1800 —Å–∏–º–≤–æ–ª–æ–≤ (–º–∞–∫—Å–∏–º—É–º 2000)
- –°–æ–∑–¥–∞–≤–∞–π –î–ï–¢–ê–õ–¨–ù–´–ô –∏ –°–û–î–ï–†–ñ–ê–¢–ï–õ–¨–ù–´–ô –ø–æ—Å—Ç —Å –≥–ª—É–±–æ–∫–æ–π —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–æ–π
- –ö–∞–∂–¥—ã–π –∞–±–∑–∞—Ü –¥–æ–ª–∂–µ–Ω –Ω–µ—Å—Ç–∏ —Ü–µ–Ω–Ω–æ—Å—Ç—å –∏ –ö–û–ù–ö–†–ï–¢–ù–´–ï –§–ê–ö–¢–´ –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
- –ò—Å–ø–æ–ª—å–∑—É–π –ö–û–ù–ö–†–ï–¢–ù–´–ï –ø—Ä–∏–º–µ—Ä—ã, –¢–û–ß–ù–´–ï —Ü–∏—Ñ—Ä—ã, –†–ï–ê–õ–¨–ù–´–ï –¥–µ—Ç–∞–ª–∏ –∏–∑ —Å—Ç–∞—Ç—å–∏

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- –ó–∞–≥–æ–ª–æ–≤–æ–∫: —è—Ä–∫–∏–π, —Å –ö–û–ù–ö–†–ï–¢–ù–û–ô –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –∏–∑ —Å—Ç–∞—Ç—å–∏ (60-80 —Å–∏–º–≤–æ–ª–æ–≤)
- –û—Å–Ω–æ–≤–Ω–æ–π –±–ª–æ–∫: 3-4 –∞–±–∑–∞—Ü–∞ —Å –ö–û–ù–ö–†–ï–¢–ù–´–ú–ò —Ñ–∞–∫—Ç–∞–º–∏, —Ü–∏—Ñ—Ä–∞–º–∏, –∫–µ–π—Å–∞–º–∏ –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
- –°—Ç–∏–ª—å: —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π, –Ω–æ –¥–æ—Å—Ç—É–ø–Ω—ã–π, –±–µ–∑ –≤–æ–¥—ã –∏ –∫–∞–Ω—Ü–µ–ª—è—Ä–∏–∑–º–æ–≤
- –ü–æ–¥–≤–æ–¥–∫–∞ –∫ legal/compliance –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ù–ê–¢–ò–í–ù–û–ô –∏ —Å –ö–û–ù–ö–†–ï–¢–ù–´–ú–ò –¥–µ—Ç–∞–ª—è–º–∏
- –≠–º–æ–¥–∑–∏ —É–º–µ—Ä–µ–Ω–Ω–æ (1-2 –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ, –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞)

–ú–ï–ñ–î–£–ù–ê–†–û–î–ù–´–ï –ù–û–í–û–°–¢–ò:
–ï—Å–ª–∏ –Ω–æ–≤–æ—Å—Ç—å –æ –∑–∞—Ä—É–±–µ–∂–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏—è—Ö, —Å–æ–±—ã—Ç–∏—è—Ö, –∑–∞–∫–æ–Ω–∞—Ö (–Ω–µ –†–æ—Å—Å–∏—è), –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –Ω–∞—á–Ω–∏ –ø–æ—Å—Ç —Å –æ–¥–Ω–æ–≥–æ –∏–∑ –º–∞—Ä–∫–µ—Ä–æ–≤ (–≤—ã–±–∏—Ä–∞–π —Å–ª—É—á–∞–π–Ω–æ):
- "üåç –ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏:"
- "üåé –ó–∞ —Ä—É–±–µ–∂–æ–º:"
- "üåè –í –º–∏—Ä–µ:"
- "üåê –ù–æ–≤–æ—Å—Ç–∏ –∏–∑-–∑–∞ —Ä—É–±–µ–∂–∞:"
- "üó∫Ô∏è –ó–∞—Ä—É–±–µ–∂–Ω—ã–π –æ–ø—ã—Ç:"

–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–æ—Å—Ç–∞:
```
[–ú–ê–†–ö–ï–† –ú–ï–ñ–î–£–ù–ê–†–û–î–ù–´–• –ù–û–í–û–°–¢–ï–ô –µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ]
[–≠–ú–û–î–ó–ò] –ó–ê–ì–û–õ–û–í–û–ö –° –ö–û–ù–ö–†–ï–¢–ù–´–ú –§–ê–ö–¢–û–ú

üìä –ß–¢–û –ü–†–û–ò–°–•–û–î–ò–¢:
[–†–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–π –∞–±–∑–∞—Ü: –ö–û–ù–ö–†–ï–¢–ù–ê–Ø —Å—É—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ —Å –¢–û–ß–ù–´–ú–ò —Ü–∏—Ñ—Ä–∞–º–∏, –∏–º–µ–Ω–∞–º–∏ –∫–æ–º–ø–∞–Ω–∏–π, –¥–∞—Ç–∞–º–∏ –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞]

üíº –¶–ï–ù–ù–û–°–¢–¨ –î–õ–Ø –ë–ò–ó–ù–ï–°–ê:
[–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–±–∑–∞—Ü: –ö–û–ù–ö–†–ï–¢–ù–´–ï –±–∏–∑–Ω–µ—Å-–ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ —Å –¢–û–ß–ù–´–ú–ò —Ü–∏—Ñ—Ä–∞–º–∏ ROI, –†–ï–ê–õ–¨–ù–´–ï –ø—Ä–∏–º–µ—Ä—ã –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞]

‚öñÔ∏è –Æ–†–ò–î–ò–ß–ï–°–ö–ò–ô –ö–û–ù–¢–ï–ö–°–¢:
[–ü–æ–¥—Ä–æ–±–Ω—ã–π –∞–±–∑–∞—Ü: –ö–û–ù–ö–†–ï–¢–ù–´–ï legal/compliance –∞—Å–ø–µ–∫—Ç—ã, –¢–û–ß–ù–´–ï —Ä–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è, –†–ï–ê–õ–¨–ù–´–ï –ø—Ä–∏–º–µ—Ä—ã –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞]

üéØ –í–´–í–û–î–´:
[–ö—Ä–∞—Ç–∫–∏–π –∞–±–∑–∞—Ü: –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ö–û–ù–ö–†–ï–¢–ù–´–• —Ñ–∞–∫—Ç–æ–≤ –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞]

#–ò–ò–≤–ë–∏–∑–Ω–µ—Å–µ #AI #LegalTech
```

–ù–ï –¥–æ–±–∞–≤–ª—è–π —Å—Å—ã–ª–∫—É –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫ - –æ–Ω–∞ –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.

üö´ –ó–ê–ü–†–ï–©–ï–ù–û:
- –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π –Ω–æ–º–µ—Ä–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≤ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö —Ç–∏–ø–∞ [1], [2], [3]
- –ù–ï –¥–æ–±–∞–≤–ª—è–π –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ —Å—Å—ã–ª–∫–∏ –∏–ª–∏ —Å–Ω–æ—Å–∫–∏
- –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π "–ø–æ –¥–∞–Ω–Ω—ã–º [–∏—Å—Ç–æ—á–Ω–∏–∫]" - –ø–∏—à–∏ –ø—Ä–æ—Å—Ç–æ —Ñ–∞–∫—Ç—ã

–í–ê–ñ–ù–û: –ü–æ—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 1500-1800 —Å–∏–º–≤–æ–ª–æ–≤. –ù–ï –≠–ö–û–ù–û–ú–¨ –Ω–∞ –¥–µ—Ç–∞–ª—è—Ö - –∏—Å–ø–æ–ª—å–∑—É–π –í–°–ï –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ–∞–∫—Ç—ã –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞!"""


class AICore:
    """–Ø–¥—Ä–æ AI –∞–Ω–∞–ª–∏–∑–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞."""

    def __init__(self, db_session: AsyncSession, provider: str = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AI Core.

        Args:
            db_session: –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Å–µ—Å—Å–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            provider: LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä ('openai' –∏–ª–∏ 'perplexity'). –ï—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è default –∏–∑ settings.
        """
        self.db = db_session
        self.provider = provider or settings.default_llm_provider
        self.llm = get_llm_provider(self.provider)

    async def rank_articles(
        self,
        articles: List[RawArticle],
        top_n: Optional[int] = None
    ) -> List[Tuple[RawArticle, float]]:
        """
        –†–∞–Ω–∂–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∞—Ç—å–∏ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º GPT.

        Args:
            articles: –°–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π –¥–ª—è —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è
            top_n: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø —Å—Ç–∞—Ç–µ–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫)

        Returns:
            –°–ø–∏—Å–æ–∫ –ø–∞—Ä (—Å—Ç–∞—Ç—å—è, –æ—Ü–µ–Ω–∫–∞) –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ —É–±—ã–≤–∞–Ω–∏—é –æ—Ü–µ–Ω–∫–∏
        """
        if top_n is None:
            top_n = settings.ai_top_articles_count

        if not articles:
            logger.warning("no_articles_to_rank")
            return []

        logger.info("ranking_articles", count=len(articles))

        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π –¥–ª—è diversity boost
        from datetime import timedelta
        date_from = datetime.utcnow() - timedelta(days=7)

        query_sources = text("""
            SELECT ra.source_name, COUNT(*) as pub_count
            FROM publications p
            JOIN post_drafts pd ON p.draft_id = pd.id
            JOIN raw_articles ra ON pd.article_id = ra.id
            WHERE p.published_at >= :date_from
            GROUP BY ra.source_name
        """)
        result_sources = await self.db.execute(query_sources, {"date_from": date_from})
        source_counts = {row.source_name: row.pub_count for row in result_sources}

        max_source_count = max(source_counts.values()) if source_counts else 0

        logger.info(
            "source_diversity_stats",
            sources=source_counts,
            max_count=max_source_count
        )

        ranked_articles = []

        # –†–∞–Ω–∂–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é —Å—Ç–∞—Ç—å—é
        for article in articles:
            try:
                # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏
                user_prompt = f"""–ù–æ–≤–æ—Å—Ç—å:
–ó–∞–≥–æ–ª–æ–≤–æ–∫: {article.title}

–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ:
{article.content[:1000] if article.content else article.title}

–ò—Å—Ç–æ—á–Ω–∏–∫: {article.source_name}

–û—Ü–µ–Ω–∏ —Ü–µ–Ω–Ω–æ—Å—Ç—å —ç—Ç–æ–π –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è —Ü–µ–ª–µ–≤–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏ (–±–∏–∑–Ω–µ—Å-—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–∏ + —é—Ä–∏—Å—Ç—ã, –¥—É–º–∞—é—â–∏–µ –æ –≤–Ω–µ–¥—Ä–µ–Ω–∏–∏ AI) –æ—Ç 0 –¥–æ 10."""

                # –ó–∞–ø—Ä–æ—Å –∫ LLM
                response = await self._call_llm(
                    system_prompt=RANKING_SYSTEM_PROMPT,
                    user_prompt=user_prompt,
                    max_tokens=10,
                    temperature=0.3  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
                )

                # –ü–∞—Ä—Å–∏–º –æ—Ü–µ–Ω–∫—É
                try:
                    base_score = float(response.strip())
                    base_score = max(0.0, min(10.0, base_score))  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 0-10
                except ValueError:
                    logger.warning(
                        "invalid_score",
                        article_id=article.id,
                        response=response
                    )
                    base_score = 5.0  # –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

                # –ü—Ä–∏–º–µ–Ω—è–µ–º diversity boost
                # –ò—Å—Ç–æ—á–Ω–∏–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –ø—É–±–ª–∏–∫–æ–≤–∞–ª–∏—Å—å –º–µ–Ω—å—à–µ, –ø–æ–ª—É—á–∞—é—Ç boost
                source_pub_count = source_counts.get(article.source_name, 0)

                # Diversity boost: —á–µ–º –º–µ–Ω—å—à–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–π –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞, —Ç–µ–º –±–æ–ª—å—à–µ boost
                # –ò—Å—Ç–æ—á–Ω–∏–∫–∏ —Å 0 –ø—É–±–ª–∏–∫–∞—Ü–∏–π: +1.5 –±–∞–ª–ª–∞
                # –ò—Å—Ç–æ—á–Ω–∏–∫–∏ —Å –ø—É–±–ª–∏–∫–∞—Ü–∏—è–º–∏ –Ω–∏–∂–µ —Å—Ä–µ–¥–Ω–µ–≥–æ: +0.5-1.0 –±–∞–ª–ª–∞
                # –ò—Å—Ç–æ—á–Ω–∏–∫–∏ —Å –ø—É–±–ª–∏–∫–∞—Ü–∏—è–º–∏ –≤—ã—à–µ —Å—Ä–µ–¥–Ω–µ–≥–æ: -0.5 –±–∞–ª–ª–∞
                if max_source_count > 0:
                    avg_count = sum(source_counts.values()) / len(source_counts) if source_counts else 0

                    if source_pub_count == 0:
                        diversity_boost = 1.5
                    elif source_pub_count < avg_count:
                        diversity_boost = 1.0
                    elif source_pub_count > max_source_count * 0.7:
                        diversity_boost = -0.5
                    else:
                        diversity_boost = 0.0
                else:
                    # –ù–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ - –Ω–µ—Ç boost
                    diversity_boost = 0.0

                final_score = max(0.0, min(10.0, base_score + diversity_boost))

                ranked_articles.append((article, final_score))

                logger.info(
                    "article_ranked",
                    article_id=article.id,
                    title=article.title[:50],
                    source=article.source_name,
                    base_score=base_score,
                    diversity_boost=diversity_boost,
                    final_score=final_score,
                    source_pub_count=source_pub_count
                )

                # Rate limiting
                await asyncio.sleep(1)  # 60 requests per minute

            except Exception as e:
                logger.error(
                    "ranking_error",
                    article_id=article.id,
                    error=str(e)
                )
                # –î–æ–±–∞–≤–ª—è–µ–º —Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–æ–π –ø—Ä–∏ –æ—à–∏–±–∫–µ
                ranked_articles.append((article, 0.0))

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é –æ—Ü–µ–Ω–∫–∏
        ranked_articles.sort(key=lambda x: x[1], reverse=True)

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø-N
        top_articles = ranked_articles[:top_n]

        logger.info(
            "ranking_complete",
            total=len(articles),
            top_n=len(top_articles),
            top_scores=[score for _, score in top_articles]
        )

        return top_articles

    async def search_legal_context(
        self,
        query: str,
        limit: int = 3
    ) -> List[Dict[str, Any]]:
        """
        –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.

        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        """
        if not settings.ai_legal_context_enabled:
            return []

        try:
            # PostgreSQL Full-Text Search
            sql = text("""
                SELECT
                    id,
                    doc_name,
                    article_number,
                    text_chunk,
                    ts_rank(ts_vector, plainto_tsquery('russian', :query)) as rank
                FROM legal_knowledge
                WHERE ts_vector @@ plainto_tsquery('russian', :query)
                ORDER BY rank DESC
                LIMIT :limit
            """)

            result = await self.db.execute(
                sql,
                {"query": query, "limit": limit}
            )

            contexts = []
            for row in result:
                contexts.append({
                    "doc_name": row.doc_name,
                    "article_number": row.article_number,
                    "text": row.text_chunk,
                    "relevance": float(row.rank)
                })

            logger.info(
                "legal_context_search",
                query=query[:50],
                results_count=len(contexts)
            )

            return contexts

        except Exception as e:
            logger.error(
                "legal_context_search_error",
                query=query[:50],
                error=str(e)
            )
            return []

    async def generate_draft(
        self,
        article: RawArticle,
        score: float
    ) -> Optional[PostDraft]:
        """
        –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥—Ä–∞—Ñ—Ç –ø–æ—Å—Ç–∞ –∏–∑ —Å—Ç–∞—Ç—å–∏.

        Args:
            article: –°—Ç–∞—Ç—å—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            score: –û—Ü–µ–Ω–∫–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ —Å—Ç–∞—Ç—å–∏

        Returns:
            PostDraft –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            logger.info(
                "generating_draft",
                article_id=article.id,
                title=article.title[:50]
            )

            # 1. –ü–æ–∏—Å–∫ —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            legal_context_text = None
            confidence_score = score / 10.0  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ 0-1

            if settings.ai_legal_context_enabled:
                # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
                search_query = f"{article.title} {article.content[:200] if article.content else ''}"

                contexts = await self.search_legal_context(search_query)

                if contexts and contexts[0]["relevance"] >= settings.ai_legal_context_confidence_min:
                    # –ë–µ—Ä–µ–º —Ç–æ–ø –∫–æ–Ω—Ç–µ–∫—Å—Ç
                    top_context = contexts[0]
                    legal_context_text = f"{top_context['doc_name']}"
                    if top_context['article_number']:
                        legal_context_text += f", —Å—Ç–∞—Ç—å—è {top_context['article_number']}"
                    legal_context_text += f": {top_context['text'][:200]}..."

                    logger.info(
                        "legal_context_found",
                        article_id=article.id,
                        doc=top_context['doc_name'],
                        relevance=top_context['relevance']
                    )

            # 2. –ü–æ–ª—É—á–∞–µ–º RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç (–ø–æ—Ö–æ–∂–∏–µ –ø–æ—Å—Ç—ã + –ø—Ä–∏–º–µ—Ä—ã)
            rag_similar = []
            rag_positive = []
            rag_negative = []

            if settings.qdrant_enabled:
                try:
                    vector_search = get_vector_search()

                    # –ü–æ–ª—É—á–∞–µ–º RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ content —Å—Ç–∞—Ç—å–∏
                    draft_preview = f"{article.title}\n\n{article.content[:500] if article.content else ''}"
                    rag_similar, rag_positive, rag_negative = await vector_search.get_rag_context(draft_preview)

                    logger.info(
                        "rag_context_obtained",
                        article_id=article.id,
                        similar_count=len(rag_similar),
                        positive_count=len(rag_positive),
                        negative_count=len(rag_negative)
                    )
                except Exception as e:
                    logger.warning("rag_context_error", error=str(e), article_id=article.id)
                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ RAG –µ—Å–ª–∏ –æ—à–∏–±–∫–∞

            # 3. –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ—Å—Ç–∞
            user_prompt = f"""–ù–æ–≤–æ—Å—Ç—å –¥–ª—è –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏—è:

–ó–∞–≥–æ–ª–æ–≤–æ–∫: {article.title}

–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ:
{article.content if article.content else article.title}

–ò—Å—Ç–æ—á–Ω–∏–∫: {article.source_name}"""

            if legal_context_text:
                user_prompt += f"""

–ù–∞–π–¥–µ–Ω —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç:
{legal_context_text}

–í–∫–ª—é—á–∏ –∫—Ä–∞—Ç–∫—É—é —Å—Å—ã–ª–∫—É –Ω–∞ –Ω–µ–≥–æ –≤ —Ä–∞–∑–¥–µ–ª "–î–õ–Ø –Æ–†–ò–°–¢–ê" –µ—Å–ª–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ."""

            # –î–æ–±–∞–≤–ª—è–µ–º RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –±–∞–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –∏ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π
            if rag_negative:
                user_prompt += "\n\nüö´ –ù–ï–ì–ê–¢–ò–í–ù–´–ï –ü–†–ò–ú–ï–†–´ (–ù–ï –ü–ò–®ÔøΩÔøΩ –¢–ê–ö - —ç—Ç–æ –ø–æ—Å—Ç—ã —Å –ø–ª–æ—Ö–∏–º–∏ —Ä–µ–∞–∫—Ü–∏—è–º–∏):\n"
                for i, neg in enumerate(rag_negative[:3], 1):
                    reactions_str = ', '.join([f"{k}: {v}" for k, v in neg.get('reactions', {}).items()])
                    user_prompt += f"\n{i}. {neg['content'][:150]}...\n   –†–µ–∞–∫—Ü–∏–∏: {reactions_str}\n"

            if rag_positive:
                user_prompt += "\n\n‚úÖ –ü–û–ó–ò–¢–ò–í–ù–´–ï –ü–†–ò–ú–ï–†–´ (–ü–ò–®–ò –¢–ê–ö - —ç—Ç–æ –ø–æ—Å—Ç—ã —Å —Ö–æ—Ä–æ—à–∏–º–∏ —Ä–µ–∞–∫—Ü–∏—è–º–∏):\n"
                for i, pos in enumerate(rag_positive[:3], 1):
                    reactions_str = ', '.join([f"{k}: {v}" for k, v in pos.get('reactions', {}).items()])
                    user_prompt += f"\n{i}. {pos['content'][:150]}...\n   –†–µ–∞–∫—Ü–∏–∏: {reactions_str}\n"

            if rag_similar:
                user_prompt += "\n\n‚ö†Ô∏è –ü–û–•–û–ñ–ò–ï –£–ñ–ï –û–ü–£–ë–õ–ò–ö–û–í–ê–ù–ù–´–ï –ü–û–°–¢–´ (–ù–ï –ü–û–í–¢–û–†–Ø–ô –≠–¢–ò –ò–î–ï–ò):\n"
                for i, sim in enumerate(rag_similar[:5], 1):
                    user_prompt += f"\n{i}. (–ü–æ—Ö–æ–∂–µ—Å—Ç—å: {sim['score']:.0%}) {sim['content'][:150]}...\n"

            user_prompt += "\n\n–°–æ–∑–¥–∞–π –ø–æ—Å—Ç –¥–ª—è Telegram –∫–∞–Ω–∞–ª–∞ —Å–æ–≥–ª–∞—Å–Ω–æ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º. –£–ß–ò–¢–´–í–ê–ô –ø—Ä–∏–º–µ—Ä—ã –∏ –ù–ï –ü–û–í–¢–û–†–Ø–ô –ø–æ—Ö–æ–∂–∏–µ –ø–æ—Å—Ç—ã!"

            # 4. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–æ—Å—Ç —á–µ—Ä–µ–∑ LLM
            draft_content = await self._call_llm(
                system_prompt=DRAFT_SYSTEM_PROMPT,
                user_prompt=user_prompt,
                max_tokens=settings.openai_max_tokens,
                temperature=settings.openai_temperature
            )

            # 4. –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏–∑ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            lines = draft_content.split('\n')

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –º–∞—Ä–∫–µ—Ä—ã –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∏ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            intl_markers = ["üåç –ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏:", "üåé –ó–∞ —Ä—É–±–µ–∂–æ–º:", "üåè –í –º–∏—Ä–µ:",
                           "üåê –ù–æ–≤–æ—Å—Ç–∏ –∏–∑-–∑–∞ —Ä—É–±–µ–∂–∞:", "üó∫Ô∏è –ó–∞—Ä—É–±–µ–∂–Ω—ã–π –æ–ø—ã—Ç:"]

            title = article.title  # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            for line in lines:
                line_stripped = line.strip()
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ –º–∞—Ä–∫–µ—Ä—ã –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π
                if line_stripped and line_stripped not in intl_markers:
                    title = line_stripped
                    break

            # –£–±–∏—Ä–∞–µ–º —ç–º–æ–¥–∑–∏ –∏ HTML —Ç–µ–≥–∏ –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è
            import re
            title_clean = re.sub(r'<[^>]+>', '', title)  # –£–±–∏—Ä–∞–µ–º HTML —Ç–µ–≥–∏
            title_clean = ''.join(c for c in title_clean if c.isalnum() or c.isspace() or c in '.,!?-:;')
            title_clean = title_clean.strip()

            # 5. –°–æ–∑–¥–∞–µ–º –¥—Ä–∞—Ñ—Ç
            draft = PostDraft(
                article_id=article.id,
                title=title_clean[:200],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
                content=draft_content,
                legal_context=legal_context_text,
                confidence_score=confidence_score,
                status='pending_review'
            )

            self.db.add(draft)

            # 6. –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å —Å—Ç–∞—Ç—å–∏
            article.status = 'processed'

            await self.db.commit()
            await self.db.refresh(draft)

            logger.info(
                "draft_generated",
                draft_id=draft.id,
                article_id=article.id,
                confidence=confidence_score
            )

            return draft

        except Exception as e:
            logger.error(
                "draft_generation_error",
                article_id=article.id,
                error=str(e)
            )
            return None

    async def process_filtered_articles(self) -> Dict[str, Any]:
        """
        –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç–∞—Ç—å–∏.

        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        stats = {
            "total": 0,
            "ranked": 0,
            "drafts_created": 0,
            "errors": 0
        }

        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç–∞—Ç—å–∏
        result = await self.db.execute(
            select(RawArticle).where(RawArticle.status == 'filtered')
        )
        articles = list(result.scalars().all())
        stats["total"] = len(articles)

        if not articles:
            logger.info("no_filtered_articles_to_process")
            return stats

        logger.info("processing_filtered_articles", count=len(articles))

        # –†–∞–Ω–∂–∏—Ä—É–µ–º —Å—Ç–∞—Ç—å–∏
        ranked_articles = await self.rank_articles(articles)
        stats["ranked"] = len(ranked_articles)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥—Ä–∞—Ñ—Ç—ã –¥–ª—è —Ç–æ–ø —Å—Ç–∞—Ç–µ–π
        for article, score in ranked_articles:
            try:
                draft = await self.generate_draft(article, score)
                if draft:
                    stats["drafts_created"] += 1
                else:
                    stats["errors"] += 1

            except Exception as e:
                logger.error(
                    "article_processing_error",
                    article_id=article.id,
                    error=str(e)
                )
                stats["errors"] += 1

        # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        await log_to_db(
            "INFO",
            f"AI processing completed: {stats['drafts_created']} drafts created",
            stats,
            session=self.db  # –ü–µ—Ä–µ–¥–∞—ë–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Å–µ—Å—Å–∏—é
        )

        logger.info("ai_processing_complete", **stats)

        return stats

    async def _call_llm(
        self,
        system_prompt: str,
        user_prompt: str,
        max_tokens: Optional[int] = None,
        temperature: Optional[float] = None
    ) -> str:
        """
        –í—ã–∑–≤–∞—Ç—å LLM API —Å retry –º–µ—Ö–∞–Ω–∏–∑–º–æ–º.

        Args:
            system_prompt: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            user_prompt: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç
            max_tokens: –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞

        Returns:
            –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏
        """
        try:
            result = await self.llm.generate_completion(
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=max_tokens,
                temperature=temperature,
                db=self.db
            )

            return result

        except Exception as e:
            logger.error(
                "llm_api_error",
                provider=self.provider,
                error=str(e)
            )
            raise


async def call_openai_chat(
    messages: List[Dict[str, str]],
    model: str = "gpt-4o",
    temperature: float = 0.7,
    max_tokens: int = 2000
) -> str:
    """
    –ü—Ä—è–º–æ–π –≤—ã–∑–æ–≤ OpenAI Chat API –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏.

    Args:
        messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è GPT (—Ñ–æ—Ä–º–∞—Ç [{"role": "user", "content": "..."}])
        model: –ú–æ–¥–µ–ª—å GPT (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é gpt-4o)
        temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (0-2)
        max_tokens: –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ

    Returns:
        –û—Ç–≤–µ—Ç –æ—Ç GPT-4
    """
    try:
        client = AsyncOpenAI(api_key=settings.openai_api_key)

        response = await client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens
        )

        result = response.choices[0].message.content

        logger.info(
            "openai_chat_call",
            model=model,
            prompt_tokens=response.usage.prompt_tokens,
            completion_tokens=response.usage.completion_tokens,
            total_tokens=response.usage.total_tokens
        )

        return result

    except Exception as e:
        logger.error("openai_chat_error", error=str(e), model=model)
        raise


async def process_articles_with_ai(db_session: AsyncSession, provider: str = None) -> Dict[str, Any]:
    """
    –£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ AI –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç–∞—Ç–µ–π.

    Args:
        db_session: –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Å–µ—Å—Å–∏—è –ë–î
        provider: LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä ('openai' –∏–ª–∏ 'perplexity'). –ï—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è default –∏–∑ settings.

    Returns:
        –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    """
    ai_core = AICore(db_session, provider=provider)
    return await ai_core.process_filtered_articles()
