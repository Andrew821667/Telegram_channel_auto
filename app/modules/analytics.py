"""
Analytics Module
–ú–æ–¥—É–ª—å –¥–ª—è —Å–±–æ—Ä–∞ –∏ –∞–Ω–∞–ª–∏–∑–∞ –º–µ—Ç—Ä–∏–∫ –∫–∞–Ω–∞–ª–∞.

–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:
1. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ –ø–µ—Ä–∏–æ–¥ (–ø—É–±–ª–∏–∫–∞—Ü–∏–∏, —Ä–µ–∞–∫—Ü–∏–∏, engagement)
2. –¢–æ–ø –ª—É—á—à–∏—Ö –∏ —Ö—É–¥—à–∏—Ö –ø–æ—Å—Ç–æ–≤
3. –ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
4. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏
5. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã Qdrant
"""

from typing import List, Dict, Optional, Tuple
from datetime import datetime, timedelta
from sqlalchemy import text, func
from sqlalchemy.ext.asyncio import AsyncSession
import structlog

logger = structlog.get_logger()


class AnalyticsService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π –∫–∞–Ω–∞–ª–∞."""

    def __init__(self, db: AsyncSession):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏.

        Args:
            db: –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Å–µ—Å—Å–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        """
        self.db = db

    async def get_period_stats(self, days: int = 7) -> Dict:
        """
        –ü–æ–ª—É—á–∏—Ç—å –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∑–∞ –ø–µ—Ä–∏–æ–¥.

        Args:
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        try:
            date_from = datetime.utcnow() - timedelta(days=days)

            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—É–±–ª–∏–∫–∞—Ü–∏–π
            query_pubs = text("""
                SELECT COUNT(*) as total_publications
                FROM publications
                WHERE published_at >= :date_from
            """)
            result_pubs = await self.db.execute(query_pubs, {"date_from": date_from})
            total_pubs = result_pubs.scalar() or 0

            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—É–±–ª–∏–∫–∞—Ü–∏–π —Å —Ä–µ–∞–∫—Ü–∏—è–º–∏ (–¥–ª—è engagement rate)
            query_engaged = text("""
                SELECT COUNT(*) as engaged_publications
                FROM publications
                WHERE published_at >= :date_from
                AND (
                    COALESCE((reactions->>'useful')::int, 0) +
                    COALESCE((reactions->>'important')::int, 0) +
                    COALESCE((reactions->>'controversial')::int, 0) +
                    COALESCE((reactions->>'banal')::int, 0) +
                    COALESCE((reactions->>'obvious')::int, 0) +
                    COALESCE((reactions->>'poor_quality')::int, 0) +
                    COALESCE((reactions->>'low_content_quality')::int, 0) +
                    COALESCE((reactions->>'bad_source')::int, 0)
                ) > 0
            """)
            result_engaged = await self.db.execute(query_engaged, {"date_from": date_from})
            engaged_pubs = result_engaged.scalar() or 0

            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥—Ä–∞—Ñ—Ç–æ–≤ (–æ–¥–æ–±—Ä–µ–Ω–Ω—ã—Ö –∏ –æ—Ç–∫–ª–æ–Ω–µ–Ω–Ω—ã—Ö)
            query_drafts = text("""
                SELECT
                    COUNT(*) as total_drafts,
                    COUNT(CASE WHEN status = 'approved' THEN 1 END) as approved_drafts,
                    COUNT(CASE WHEN status = 'rejected' THEN 1 END) as rejected_drafts
                FROM post_drafts
                WHERE created_at >= :date_from
            """)
            result_drafts = await self.db.execute(query_drafts, {"date_from": date_from})
            drafts_row = result_drafts.fetchone()

            total_drafts = drafts_row.total_drafts or 0
            approved_drafts = drafts_row.approved_drafts or 0
            rejected_drafts = drafts_row.rejected_drafts or 0

            # –ê–≥—Ä–µ–≥–∞—Ü–∏—è —Ä–µ–∞–∫—Ü–∏–π
            query_reactions = text("""
                SELECT
                    SUM(COALESCE((reactions->>'useful')::int, 0)) as useful,
                    SUM(COALESCE((reactions->>'important')::int, 0)) as important,
                    SUM(COALESCE((reactions->>'controversial')::int, 0)) as controversial,
                    SUM(COALESCE((reactions->>'banal')::int, 0)) as banal,
                    SUM(COALESCE((reactions->>'obvious')::int, 0)) as obvious,
                    SUM(COALESCE((reactions->>'poor_quality')::int, 0)) as poor_quality,
                    SUM(COALESCE((reactions->>'low_content_quality')::int, 0)) as low_content_quality,
                    SUM(COALESCE((reactions->>'bad_source')::int, 0)) as bad_source
                FROM publications
                WHERE published_at >= :date_from
            """)
            result_reactions = await self.db.execute(query_reactions, {"date_from": date_from})
            reactions_row = result_reactions.fetchone()

            reactions = {
                "useful": reactions_row.useful or 0,
                "important": reactions_row.important or 0,
                "controversial": reactions_row.controversial or 0,
                "banal": reactions_row.banal or 0,
                "obvious": reactions_row.obvious or 0,
                "poor_quality": reactions_row.poor_quality or 0,
                "low_content_quality": reactions_row.low_content_quality or 0,
                "bad_source": reactions_row.bad_source or 0
            }

            total_reactions = sum(reactions.values())

            # –°—Ä–µ–¥–Ω–∏–π quality score
            if total_pubs > 0:
                query_avg_score = text("""
                    SELECT AVG(
                        (
                            COALESCE((reactions->>'useful')::int, 0) +
                            COALESCE((reactions->>'important')::int, 0) -
                            COALESCE((reactions->>'banal')::int, 0) -
                            COALESCE((reactions->>'obvious')::int, 0) -
                            COALESCE((reactions->>'poor_quality')::int, 0) -
                            COALESCE((reactions->>'low_content_quality')::int, 0) -
                            COALESCE((reactions->>'bad_source')::int, 0)
                        )::float / NULLIF(
                            COALESCE((reactions->>'useful')::int, 0) +
                            COALESCE((reactions->>'important')::int, 0) +
                            COALESCE((reactions->>'banal')::int, 0) +
                            COALESCE((reactions->>'obvious')::int, 0) +
                            COALESCE((reactions->>'poor_quality')::int, 0) +
                            COALESCE((reactions->>'low_content_quality')::int, 0) +
                            COALESCE((reactions->>'bad_source')::int, 0) +
                            COALESCE((reactions->>'controversial')::int, 0),
                            0
                        )
                    ) as avg_quality_score
                    FROM publications
                    WHERE published_at >= :date_from
                    AND (
                        COALESCE((reactions->>'useful')::int, 0) +
                        COALESCE((reactions->>'important')::int, 0) +
                        COALESCE((reactions->>'banal')::int, 0) +
                        COALESCE((reactions->>'obvious')::int, 0) +
                        COALESCE((reactions->>'poor_quality')::int, 0) +
                        COALESCE((reactions->>'low_content_quality')::int, 0) +
                        COALESCE((reactions->>'bad_source')::int, 0) +
                        COALESCE((reactions->>'controversial')::int, 0)
                    ) > 0
                """)
                result_avg = await self.db.execute(query_avg_score, {"date_from": date_from})
                avg_quality_score = result_avg.scalar() or 0.0
            else:
                avg_quality_score = 0.0

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º engagement rate
            engagement_rate = (engaged_pubs / total_pubs * 100) if total_pubs > 0 else 0

            return {
                "period_days": days,
                "total_publications": total_pubs,
                "engaged_publications": engaged_pubs,
                "engagement_rate": round(engagement_rate, 1),
                "total_drafts": total_drafts,
                "approved_drafts": approved_drafts,
                "rejected_drafts": rejected_drafts,
                "approval_rate": (approved_drafts / total_drafts * 100) if total_drafts > 0 else 0,
                "reactions": reactions,
                "total_reactions": total_reactions,
                "avg_quality_score": round(avg_quality_score, 2)
            }

        except Exception as e:
            logger.error("get_period_stats_error", error=str(e), days=days)
            raise

    async def get_top_posts(self, limit: int = 3, days: int = 7) -> List[Dict]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Ç–æ–ø –ø–æ—Å—Ç–æ–≤ –ø–æ quality score.

        Args:
            limit: –ú–∞–∫—Å–∏–º—É–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –°–ø–∏—Å–æ–∫ –ø–æ—Å—Ç–æ–≤ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        try:
            date_from = datetime.utcnow() - timedelta(days=days)

            query = text("""
                SELECT
                    p.id,
                    d.title,
                    d.content,
                    p.published_at,
                    p.message_id as telegram_message_id,
                    p.reactions,
                    (
                        COALESCE((p.reactions->>'useful')::int, 0) +
                        COALESCE((p.reactions->>'important')::int, 0) -
                        COALESCE((p.reactions->>'banal')::int, 0) -
                        COALESCE((p.reactions->>'obvious')::int, 0) -
                        COALESCE((p.reactions->>'poor_quality')::int, 0)
                    )::float / NULLIF(
                        COALESCE((p.reactions->>'useful')::int, 0) +
                        COALESCE((p.reactions->>'important')::int, 0) +
                        COALESCE((p.reactions->>'banal')::int, 0) +
                        COALESCE((p.reactions->>'obvious')::int, 0) +
                        COALESCE((p.reactions->>'poor_quality')::int, 0) +
                        COALESCE((p.reactions->>'controversial')::int, 0),
                        0
                    ) as quality_score,
                    (
                        COALESCE((p.reactions->>'useful')::int, 0) +
                        COALESCE((p.reactions->>'important')::int, 0) +
                        COALESCE((p.reactions->>'banal')::int, 0) +
                        COALESCE((p.reactions->>'obvious')::int, 0) +
                        COALESCE((p.reactions->>'poor_quality')::int, 0) +
                        COALESCE((p.reactions->>'controversial')::int, 0)
                    ) as total_reactions
                FROM publications p
                JOIN post_drafts d ON p.draft_id = d.id
                WHERE p.published_at >= :date_from
                AND (
                    COALESCE((p.reactions->>'useful')::int, 0) +
                    COALESCE((p.reactions->>'important')::int, 0) +
                    COALESCE((p.reactions->>'banal')::int, 0) +
                    COALESCE((p.reactions->>'obvious')::int, 0) +
                    COALESCE((p.reactions->>'poor_quality')::int, 0) +
                    COALESCE((p.reactions->>'controversial')::int, 0)
                ) > 0
                ORDER BY quality_score DESC, total_reactions DESC
                LIMIT :limit
            """)

            result = await self.db.execute(query, {
                "date_from": date_from,
                "limit": limit
            })

            posts = []
            for row in result.fetchall():
                posts.append({
                    "id": row.id,
                    "title": row.title,
                    "content": row.content,
                    "published_at": row.published_at,
                    "telegram_message_id": row.telegram_message_id,
                    "reactions": row.reactions or {},
                    "quality_score": round(row.quality_score or 0, 2),
                    "total_reactions": row.total_reactions or 0
                })

            return posts

        except Exception as e:
            logger.error("get_top_posts_error", error=str(e), limit=limit, days=days)
            return []

    async def get_worst_posts(self, limit: int = 3, days: int = 7) -> List[Dict]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Ö—É–¥—à–∏–µ –ø–æ—Å—Ç—ã –ø–æ quality score.

        Args:
            limit: –ú–∞–∫—Å–∏–º—É–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –°–ø–∏—Å–æ–∫ –ø–æ—Å—Ç–æ–≤ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        try:
            date_from = datetime.utcnow() - timedelta(days=days)

            query = text("""
                SELECT
                    p.id,
                    d.title,
                    d.content,
                    p.published_at,
                    p.message_id as telegram_message_id,
                    p.reactions,
                    (
                        COALESCE((p.reactions->>'useful')::int, 0) +
                        COALESCE((p.reactions->>'important')::int, 0) -
                        COALESCE((p.reactions->>'banal')::int, 0) -
                        COALESCE((p.reactions->>'obvious')::int, 0) -
                        COALESCE((p.reactions->>'poor_quality')::int, 0)
                    )::float / NULLIF(
                        COALESCE((p.reactions->>'useful')::int, 0) +
                        COALESCE((p.reactions->>'important')::int, 0) +
                        COALESCE((p.reactions->>'banal')::int, 0) +
                        COALESCE((p.reactions->>'obvious')::int, 0) +
                        COALESCE((p.reactions->>'poor_quality')::int, 0) +
                        COALESCE((p.reactions->>'controversial')::int, 0),
                        0
                    ) as quality_score,
                    (
                        COALESCE((p.reactions->>'useful')::int, 0) +
                        COALESCE((p.reactions->>'important')::int, 0) +
                        COALESCE((p.reactions->>'banal')::int, 0) +
                        COALESCE((p.reactions->>'obvious')::int, 0) +
                        COALESCE((p.reactions->>'poor_quality')::int, 0) +
                        COALESCE((p.reactions->>'controversial')::int, 0)
                    ) as total_reactions
                FROM publications p
                JOIN post_drafts d ON p.draft_id = d.id
                WHERE p.published_at >= :date_from
                AND (
                    COALESCE((p.reactions->>'banal')::int, 0) +
                    COALESCE((p.reactions->>'obvious')::int, 0) +
                    COALESCE((p.reactions->>'poor_quality')::int, 0)
                ) > 0
                ORDER BY quality_score ASC, total_reactions DESC
                LIMIT :limit
            """)

            result = await self.db.execute(query, {
                "date_from": date_from,
                "limit": limit
            })

            posts = []
            for row in result.fetchall():
                posts.append({
                    "id": row.id,
                    "title": row.title,
                    "content": row.content,
                    "published_at": row.published_at,
                    "telegram_message_id": row.telegram_message_id,
                    "reactions": row.reactions or {},
                    "quality_score": round(row.quality_score or 0, 2),
                    "total_reactions": row.total_reactions or 0
                })

            return posts

        except Exception as e:
            logger.error("get_worst_posts_error", error=str(e), limit=limit, days=days)
            return []

    async def get_source_stats(self, days: int = 7) -> List[Dict]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º.

        Args:
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –°–ø–∏—Å–æ–∫ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        try:
            date_from = datetime.utcnow() - timedelta(days=days)

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å—ã—Ä—ã–º —Å—Ç–∞—Ç—å—è–º (—Å–æ–±—Ä–∞–Ω–æ –Ω–æ–≤–æ—Å—Ç–µ–π)
            query_raw = text("""
                SELECT
                    source_name,
                    COUNT(*) as total_collected
                FROM raw_articles
                WHERE fetched_at >= :date_from
                GROUP BY source_name
                ORDER BY total_collected DESC
            """)
            result_raw = await self.db.execute(query_raw, {"date_from": date_from})

            sources_collected = {}
            for row in result_raw.fetchall():
                sources_collected[row.source_name] = row.total_collected

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–º –ø–æ—Å—Ç–∞–º
            query_pubs = text("""
                SELECT
                    a.source_name,
                    COUNT(*) as total_published,
                    AVG(
                        (
                            COALESCE((p.reactions->>'useful')::int, 0) +
                            COALESCE((p.reactions->>'important')::int, 0) -
                            COALESCE((p.reactions->>'banal')::int, 0) -
                            COALESCE((p.reactions->>'obvious')::int, 0) -
                            COALESCE((p.reactions->>'poor_quality')::int, 0)
                        )::float / NULLIF(
                            COALESCE((p.reactions->>'useful')::int, 0) +
                            COALESCE((p.reactions->>'important')::int, 0) +
                            COALESCE((p.reactions->>'banal')::int, 0) +
                            COALESCE((p.reactions->>'obvious')::int, 0) +
                            COALESCE((p.reactions->>'poor_quality')::int, 0) +
                            COALESCE((p.reactions->>'controversial')::int, 0),
                            0
                        )
                    ) as avg_quality_score
                FROM publications p
                JOIN post_drafts d ON p.draft_id = d.id
                JOIN raw_articles a ON d.article_id = a.id
                WHERE p.published_at >= :date_from
                GROUP BY a.source_name
            """)
            result_pubs = await self.db.execute(query_pubs, {"date_from": date_from})

            sources = []
            for row in result_pubs.fetchall():
                source_name = row.source_name
                total_collected = sources_collected.get(source_name, 0)
                total_published = row.total_published or 0

                sources.append({
                    "source_name": source_name,
                    "total_collected": total_collected,
                    "total_published": total_published,
                    "publication_rate": (total_published / total_collected * 100) if total_collected > 0 else 0,
                    "avg_quality_score": round(row.avg_quality_score or 0, 2)
                })

            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
            sources.sort(key=lambda x: x["avg_quality_score"], reverse=True)

            return sources

        except Exception as e:
            logger.error("get_source_stats_error", error=str(e), days=days)
            return []

    async def get_weekday_stats(self, days: int = 30) -> Dict:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏.

        Args:
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–º–∏–Ω–∏–º—É–º 7)

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏
        """
        try:
            date_from = datetime.utcnow() - timedelta(days=days)

            query = text("""
                SELECT
                    EXTRACT(DOW FROM published_at) as day_of_week,
                    COUNT(*) as total_posts,
                    AVG(
                        (
                            COALESCE((reactions->>'useful')::int, 0) +
                            COALESCE((reactions->>'important')::int, 0) -
                            COALESCE((reactions->>'banal')::int, 0) -
                            COALESCE((reactions->>'obvious')::int, 0) -
                            COALESCE((reactions->>'poor_quality')::int, 0)
                        )::float / NULLIF(
                            COALESCE((reactions->>'useful')::int, 0) +
                            COALESCE((reactions->>'important')::int, 0) +
                            COALESCE((reactions->>'banal')::int, 0) +
                            COALESCE((reactions->>'obvious')::int, 0) +
                            COALESCE((reactions->>'poor_quality')::int, 0) +
                            COALESCE((reactions->>'controversial')::int, 0),
                            0
                        )
                    ) as avg_quality_score
                FROM publications
                WHERE published_at >= :date_from
                GROUP BY day_of_week
                ORDER BY day_of_week
            """)

            result = await self.db.execute(query, {"date_from": date_from})

            # –ú–∞–ø–ø–∏–Ω–≥ –¥–Ω–µ–π –Ω–µ–¥–µ–ª–∏ (0=–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ, 1=–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫, ...)
            day_names = {
                0: "–í—Å",
                1: "–ü–Ω",
                2: "–í—Ç",
                3: "–°—Ä",
                4: "–ß—Ç",
                5: "–ü—Ç",
                6: "–°–±"
            }

            weekday_stats = {}
            for row in result.fetchall():
                day_num = int(row.day_of_week)
                day_name = day_names.get(day_num, "??")

                weekday_stats[day_name] = {
                    "total_posts": row.total_posts or 0,
                    "avg_quality_score": round(row.avg_quality_score or 0, 2)
                }

            return weekday_stats

        except Exception as e:
            logger.error("get_weekday_stats_error", error=str(e), days=days)
            return {}

    async def get_vector_db_stats(self) -> Optional[Dict]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã Qdrant.

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ Qdrant –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
        """
        try:
            from app.modules.vector_search import get_vector_search
            from app.config import settings

            if not getattr(settings, "qdrant_enabled", False):
                return None

            vector_search = get_vector_search()

            # –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
            collection_info = vector_search.client.get_collection(
                collection_name=vector_search.COLLECTION_NAME
            )

            total_vectors = collection_info.points_count

            # –ü–æ–¥—Å—á–∏—Ç–∞—Ç—å –≤–µ–∫—Ç–æ—Ä—ã —Å —Ä–∞–∑–Ω—ã–º–∏ quality_score
            # Scroll —á–µ—Ä–µ–∑ –≤—Å–µ —Ç–æ—á–∫–∏ –∏ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞—Ç—å
            positive_count = 0
            negative_count = 0
            neutral_count = 0
            total_score = 0.0

            offset = None
            while True:
                results, next_offset = vector_search.client.scroll(
                    collection_name=vector_search.COLLECTION_NAME,
                    limit=100,
                    offset=offset,
                    with_payload=True,
                    with_vectors=False
                )

                if not results:
                    break

                for point in results:
                    quality_score = point.payload.get("quality_score", 0.0)
                    total_score += quality_score

                    if quality_score > 0.5:
                        positive_count += 1
                    elif quality_score < -0.3:
                        negative_count += 1
                    else:
                        neutral_count += 1

                offset = next_offset
                if offset is None:
                    break

            avg_score = (total_score / total_vectors) if total_vectors > 0 else 0.0

            return {
                "total_vectors": total_vectors,
                "positive_examples": positive_count,
                "negative_examples": negative_count,
                "neutral_examples": neutral_count,
                "avg_quality_score": round(avg_score, 2)
            }

        except Exception as e:
            logger.error("get_vector_db_stats_error", error=str(e))
            return None

    async def get_source_recommendations(self, days: int = 30) -> List[Dict]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º (–∫–∞–∫–∏–µ —Å—Ç–æ–∏—Ç –æ—Ç–∫–ª—é—á–∏—Ç—å).

        Args:
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –°–ø–∏—Å–æ–∫ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
        """
        try:
            date_from = datetime.utcnow() - timedelta(days=days)

            # –ù–∞—Ö–æ–¥–∏–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Å –Ω–∏–∑–∫–∏–º –∫–∞—á–µ—Å—Ç–≤–æ–º
            query = text("""
                SELECT
                    ra.source_name,
                    COUNT(p.id) as total_publications,
                    AVG(
                        (
                            COALESCE((p.reactions->>'useful')::int, 0) +
                            COALESCE((p.reactions->>'important')::int, 0) -
                            COALESCE((p.reactions->>'banal')::int, 0) -
                            COALESCE((p.reactions->>'obvious')::int, 0) -
                            COALESCE((p.reactions->>'poor_quality')::int, 0) -
                            COALESCE((p.reactions->>'low_content_quality')::int, 0) -
                            COALESCE((p.reactions->>'bad_source')::int, 0)
                        )::float / NULLIF(
                            COALESCE((p.reactions->>'useful')::int, 0) +
                            COALESCE((p.reactions->>'important')::int, 0) +
                            COALESCE((p.reactions->>'banal')::int, 0) +
                            COALESCE((p.reactions->>'obvious')::int, 0) +
                            COALESCE((p.reactions->>'poor_quality')::int, 0) +
                            COALESCE((p.reactions->>'low_content_quality')::int, 0) +
                            COALESCE((p.reactions->>'bad_source')::int, 0) +
                            COALESCE((p.reactions->>'controversial')::int, 0),
                            0
                        )
                    ) as avg_quality_score,
                    SUM(COALESCE((p.reactions->>'bad_source')::int, 0)) as bad_source_reactions,
                    SUM(COALESCE((p.reactions->>'low_content_quality')::int, 0)) as low_quality_reactions
                FROM publications p
                JOIN post_drafts pd ON p.draft_id = pd.id
                JOIN raw_articles ra ON pd.article_id = ra.id
                WHERE p.published_at >= :date_from
                GROUP BY ra.source_name
                HAVING COUNT(p.id) >= 2
            """)

            result = await self.db.execute(query, {"date_from": date_from})

            recommendations = []
            for row in result.fetchall():
                avg_score = row.avg_quality_score or 0.0
                bad_source_count = row.bad_source_reactions or 0
                low_quality_count = row.low_quality_reactions or 0
                total_pubs = row.total_publications

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é
                recommendation = None
                severity = None

                if avg_score < -0.4 and bad_source_count >= 2:
                    recommendation = "üö´ –û–¢–ö–õ–Æ–ß–ò–¢–¨: –ù–µ–Ω–∞–¥–µ–∂–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ —Å –Ω–∏–∑–∫–∏–º –∫–∞—á–µ—Å—Ç–≤–æ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"
                    severity = "critical"
                elif avg_score < -0.3 and (bad_source_count >= 1 or low_quality_count >= 2):
                    recommendation = "‚ö†Ô∏è –ü–†–û–í–ï–†–ò–¢–¨: –ò—Å—Ç–æ—á–Ω–∏–∫ —Å –ø—Ä–æ–±–ª–µ–º–∞–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞"
                    severity = "warning"
                elif avg_score < 0.0 and total_pubs >= 5:
                    recommendation = "üí° –ü–ï–†–ï–°–ú–û–¢–†–ï–¢–¨: –ò—Å—Ç–æ—á–Ω–∏–∫ —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º–∏ —Ä–µ–∞–∫—Ü–∏—è–º–∏"
                    severity = "info"

                if recommendation:
                    recommendations.append({
                        "source_name": row.source_name,
                        "total_publications": total_pubs,
                        "avg_quality_score": round(avg_score, 2),
                        "bad_source_reactions": bad_source_count,
                        "low_quality_reactions": low_quality_count,
                        "recommendation": recommendation,
                        "severity": severity
                    })

            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç–∏ (critical > warning > info)
            severity_order = {"critical": 0, "warning": 1, "info": 2}
            recommendations.sort(key=lambda x: (severity_order.get(x["severity"], 999), x["avg_quality_score"]))

            return recommendations

        except Exception as e:
            logger.error("get_source_recommendations_error", error=str(e), days=days)
            return []
