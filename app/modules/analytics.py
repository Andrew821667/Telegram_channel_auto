"""
Analytics Module
–ú–æ–¥—É–ª—å –¥–ª—è —Å–±–æ—Ä–∞ –∏ –∞–Ω–∞–ª–∏–∑–∞ –º–µ—Ç—Ä–∏–∫ –∫–∞–Ω–∞–ª–∞.

–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:
1. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ –ø–µ—Ä–∏–æ–¥ (–ø—É–±–ª–∏–∫–∞—Ü–∏–∏, —Ä–µ–∞–∫—Ü–∏–∏, engagement)
2. –¢–æ–ø –ª—É—á—à–∏—Ö –∏ —Ö—É–¥—à–∏—Ö –ø–æ—Å—Ç–æ–≤
3. –ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
4. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏
5. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã Qdrant
"""

from typing import List, Dict, Optional, Tuple
from datetime import datetime, timedelta
from sqlalchemy import text, func
from sqlalchemy.ext.asyncio import AsyncSession
import structlog

logger = structlog.get_logger()


class AnalyticsService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π –∫–∞–Ω–∞–ª–∞."""

    def __init__(self, db: AsyncSession):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏.

        Args:
            db: –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Å–µ—Å—Å–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        """
        self.db = db

    async def get_period_stats(self, days: int = 7) -> Dict:
        """
        –ü–æ–ª—É—á–∏—Ç—å –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∑–∞ –ø–µ—Ä–∏–æ–¥.

        Args:
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        try:
            date_from = datetime.utcnow() - timedelta(days=days)

            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—É–±–ª–∏–∫–∞—Ü–∏–π
            query_pubs = text("""
                SELECT COUNT(*) as total_publications
                FROM publications
                WHERE published_at >= :date_from
            """)
            result_pubs = await self.db.execute(query_pubs, {"date_from": date_from})
            total_pubs = result_pubs.scalar() or 0

            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—É–±–ª–∏–∫–∞—Ü–∏–π —Å —Ä–µ–∞–∫—Ü–∏—è–º–∏ (–¥–ª—è engagement rate)
            query_engaged = text("""
                SELECT COUNT(*) as engaged_publications
                FROM publications
                WHERE published_at >= :date_from
                AND (
                    COALESCE((reactions->>'useful')::int, 0) +
                    COALESCE((reactions->>'important')::int, 0) +
                    COALESCE((reactions->>'controversial')::int, 0) +
                    COALESCE((reactions->>'banal')::int, 0) +
                    COALESCE((reactions->>'obvious')::int, 0) +
                    COALESCE((reactions->>'poor_quality')::int, 0) +
                    COALESCE((reactions->>'low_content_quality')::int, 0) +
                    COALESCE((reactions->>'bad_source')::int, 0)
                ) > 0
            """)
            result_engaged = await self.db.execute(query_engaged, {"date_from": date_from})
            engaged_pubs = result_engaged.scalar() or 0

            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥—Ä–∞—Ñ—Ç–æ–≤ (–æ–¥–æ–±—Ä–µ–Ω–Ω—ã—Ö –∏ –æ—Ç–∫–ª–æ–Ω–µ–Ω–Ω—ã—Ö)
            query_drafts = text("""
                SELECT
                    COUNT(*) as total_drafts,
                    COUNT(CASE WHEN status = 'approved' THEN 1 END) as approved_drafts,
                    COUNT(CASE WHEN status = 'rejected' THEN 1 END) as rejected_drafts
                FROM post_drafts
                WHERE created_at >= :date_from
            """)
            result_drafts = await self.db.execute(query_drafts, {"date_from": date_from})
            drafts_row = result_drafts.fetchone()

            total_drafts = drafts_row.total_drafts or 0
            approved_drafts = drafts_row.approved_drafts or 0
            rejected_drafts = drafts_row.rejected_drafts or 0

            # –ê–≥—Ä–µ–≥–∞—Ü–∏—è —Ä–µ–∞–∫—Ü–∏–π
            query_reactions = text("""
                SELECT
                    SUM(COALESCE((reactions->>'useful')::int, 0)) as useful,
                    SUM(COALESCE((reactions->>'important')::int, 0)) as important,
                    SUM(COALESCE((reactions->>'controversial')::int, 0)) as controversial,
                    SUM(COALESCE((reactions->>'banal')::int, 0)) as banal,
                    SUM(COALESCE((reactions->>'obvious')::int, 0)) as obvious,
                    SUM(COALESCE((reactions->>'poor_quality')::int, 0)) as poor_quality,
                    SUM(COALESCE((reactions->>'low_content_quality')::int, 0)) as low_content_quality,
                    SUM(COALESCE((reactions->>'bad_source')::int, 0)) as bad_source
                FROM publications
                WHERE published_at >= :date_from
            """)
            result_reactions = await self.db.execute(query_reactions, {"date_from": date_from})
            reactions_row = result_reactions.fetchone()

            reactions = {
                "useful": reactions_row.useful or 0,
                "important": reactions_row.important or 0,
                "controversial": reactions_row.controversial or 0,
                "banal": reactions_row.banal or 0,
                "obvious": reactions_row.obvious or 0,
                "poor_quality": reactions_row.poor_quality or 0,
                "low_content_quality": reactions_row.low_content_quality or 0,
                "bad_source": reactions_row.bad_source or 0
            }

            total_reactions = sum(reactions.values())

            # –°—Ä–µ–¥–Ω–∏–π quality score
            if total_pubs > 0:
                query_avg_score = text("""
                    SELECT AVG(
                        (
                            COALESCE((reactions->>'useful')::int, 0) +
                            COALESCE((reactions->>'important')::int, 0) -
                            COALESCE((reactions->>'banal')::int, 0) -
                            COALESCE((reactions->>'obvious')::int, 0) -
                            COALESCE((reactions->>'poor_quality')::int, 0) -
                            COALESCE((reactions->>'low_content_quality')::int, 0) -
                            COALESCE((reactions->>'bad_source')::int, 0)
                        )::float / NULLIF(
                            COALESCE((reactions->>'useful')::int, 0) +
                            COALESCE((reactions->>'important')::int, 0) +
                            COALESCE((reactions->>'banal')::int, 0) +
                            COALESCE((reactions->>'obvious')::int, 0) +
                            COALESCE((reactions->>'poor_quality')::int, 0) +
                            COALESCE((reactions->>'low_content_quality')::int, 0) +
                            COALESCE((reactions->>'bad_source')::int, 0) +
                            COALESCE((reactions->>'controversial')::int, 0),
                            0
                        )
                    ) as avg_quality_score
                    FROM publications
                    WHERE published_at >= :date_from
                    AND (
                        COALESCE((reactions->>'useful')::int, 0) +
                        COALESCE((reactions->>'important')::int, 0) +
                        COALESCE((reactions->>'banal')::int, 0) +
                        COALESCE((reactions->>'obvious')::int, 0) +
                        COALESCE((reactions->>'poor_quality')::int, 0) +
                        COALESCE((reactions->>'low_content_quality')::int, 0) +
                        COALESCE((reactions->>'bad_source')::int, 0) +
                        COALESCE((reactions->>'controversial')::int, 0)
                    ) > 0
                """)
                result_avg = await self.db.execute(query_avg_score, {"date_from": date_from})
                avg_quality_score = result_avg.scalar() or 0.0
            else:
                avg_quality_score = 0.0

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º engagement rate
            engagement_rate = (engaged_pubs / total_pubs * 100) if total_pubs > 0 else 0

            return {
                "period_days": days,
                "total_publications": total_pubs,
                "engaged_publications": engaged_pubs,
                "engagement_rate": round(engagement_rate, 1),
                "total_drafts": total_drafts,
                "approved_drafts": approved_drafts,
                "rejected_drafts": rejected_drafts,
                "approval_rate": (approved_drafts / total_drafts * 100) if total_drafts > 0 else 0,
                "reactions": reactions,
                "total_reactions": total_reactions,
                "avg_quality_score": round(avg_quality_score, 2)
            }

        except Exception as e:
            logger.error("get_period_stats_error", error=str(e), days=days)
            raise

    async def get_top_posts(self, limit: int = 3, days: int = 7) -> List[Dict]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Ç–æ–ø –ø–æ—Å—Ç–æ–≤ –ø–æ quality score.

        Args:
            limit: –ú–∞–∫—Å–∏–º—É–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –°–ø–∏—Å–æ–∫ –ø–æ—Å—Ç–æ–≤ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        try:
            date_from = datetime.utcnow() - timedelta(days=days)

            query = text("""
                SELECT
                    p.id,
                    d.title,
                    d.content,
                    p.published_at,
                    p.message_id as telegram_message_id,
                    p.reactions,
                    (
                        COALESCE((p.reactions->>'useful')::int, 0) +
                        COALESCE((p.reactions->>'important')::int, 0) -
                        COALESCE((p.reactions->>'banal')::int, 0) -
                        COALESCE((p.reactions->>'obvious')::int, 0) -
                        COALESCE((p.reactions->>'poor_quality')::int, 0)
                    )::float / NULLIF(
                        COALESCE((p.reactions->>'useful')::int, 0) +
                        COALESCE((p.reactions->>'important')::int, 0) +
                        COALESCE((p.reactions->>'banal')::int, 0) +
                        COALESCE((p.reactions->>'obvious')::int, 0) +
                        COALESCE((p.reactions->>'poor_quality')::int, 0) +
                        COALESCE((p.reactions->>'controversial')::int, 0),
                        0
                    ) as quality_score,
                    (
                        COALESCE((p.reactions->>'useful')::int, 0) +
                        COALESCE((p.reactions->>'important')::int, 0) +
                        COALESCE((p.reactions->>'banal')::int, 0) +
                        COALESCE((p.reactions->>'obvious')::int, 0) +
                        COALESCE((p.reactions->>'poor_quality')::int, 0) +
                        COALESCE((p.reactions->>'controversial')::int, 0)
                    ) as total_reactions
                FROM publications p
                JOIN post_drafts d ON p.draft_id = d.id
                WHERE p.published_at >= :date_from
                AND (
                    COALESCE((p.reactions->>'useful')::int, 0) +
                    COALESCE((p.reactions->>'important')::int, 0) +
                    COALESCE((p.reactions->>'banal')::int, 0) +
                    COALESCE((p.reactions->>'obvious')::int, 0) +
                    COALESCE((p.reactions->>'poor_quality')::int, 0) +
                    COALESCE((p.reactions->>'controversial')::int, 0)
                ) > 0
                ORDER BY quality_score DESC, total_reactions DESC
                LIMIT :limit
            """)

            result = await self.db.execute(query, {
                "date_from": date_from,
                "limit": limit
            })

            posts = []
            for row in result.fetchall():
                posts.append({
                    "id": row.id,
                    "title": row.title,
                    "content": row.content,
                    "published_at": row.published_at,
                    "telegram_message_id": row.telegram_message_id,
                    "reactions": row.reactions or {},
                    "quality_score": round(row.quality_score or 0, 2),
                    "total_reactions": row.total_reactions or 0
                })

            return posts

        except Exception as e:
            logger.error("get_top_posts_error", error=str(e), limit=limit, days=days)
            return []

    async def get_worst_posts(self, limit: int = 3, days: int = 7) -> List[Dict]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Ö—É–¥—à–∏–µ –ø–æ—Å—Ç—ã –ø–æ quality score.

        Args:
            limit: –ú–∞–∫—Å–∏–º—É–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –°–ø–∏—Å–æ–∫ –ø–æ—Å—Ç–æ–≤ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        try:
            date_from = datetime.utcnow() - timedelta(days=days)

            query = text("""
                SELECT
                    p.id,
                    d.title,
                    d.content,
                    p.published_at,
                    p.message_id as telegram_message_id,
                    p.reactions,
                    (
                        COALESCE((p.reactions->>'useful')::int, 0) +
                        COALESCE((p.reactions->>'important')::int, 0) -
                        COALESCE((p.reactions->>'banal')::int, 0) -
                        COALESCE((p.reactions->>'obvious')::int, 0) -
                        COALESCE((p.reactions->>'poor_quality')::int, 0)
                    )::float / NULLIF(
                        COALESCE((p.reactions->>'useful')::int, 0) +
                        COALESCE((p.reactions->>'important')::int, 0) +
                        COALESCE((p.reactions->>'banal')::int, 0) +
                        COALESCE((p.reactions->>'obvious')::int, 0) +
                        COALESCE((p.reactions->>'poor_quality')::int, 0) +
                        COALESCE((p.reactions->>'controversial')::int, 0),
                        0
                    ) as quality_score,
                    (
                        COALESCE((p.reactions->>'useful')::int, 0) +
                        COALESCE((p.reactions->>'important')::int, 0) +
                        COALESCE((p.reactions->>'banal')::int, 0) +
                        COALESCE((p.reactions->>'obvious')::int, 0) +
                        COALESCE((p.reactions->>'poor_quality')::int, 0) +
                        COALESCE((p.reactions->>'controversial')::int, 0)
                    ) as total_reactions
                FROM publications p
                JOIN post_drafts d ON p.draft_id = d.id
                WHERE p.published_at >= :date_from
                AND (
                    COALESCE((p.reactions->>'banal')::int, 0) +
                    COALESCE((p.reactions->>'obvious')::int, 0) +
                    COALESCE((p.reactions->>'poor_quality')::int, 0)
                ) > 0
                ORDER BY quality_score ASC, total_reactions DESC
                LIMIT :limit
            """)

            result = await self.db.execute(query, {
                "date_from": date_from,
                "limit": limit
            })

            posts = []
            for row in result.fetchall():
                posts.append({
                    "id": row.id,
                    "title": row.title,
                    "content": row.content,
                    "published_at": row.published_at,
                    "telegram_message_id": row.telegram_message_id,
                    "reactions": row.reactions or {},
                    "quality_score": round(row.quality_score or 0, 2),
                    "total_reactions": row.total_reactions or 0
                })

            return posts

        except Exception as e:
            logger.error("get_worst_posts_error", error=str(e), limit=limit, days=days)
            return []

    async def get_source_stats(self, days: int = 7) -> List[Dict]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º.

        Args:
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –°–ø–∏—Å–æ–∫ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        try:
            date_from = datetime.utcnow() - timedelta(days=days)

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å—ã—Ä—ã–º —Å—Ç–∞—Ç—å—è–º (—Å–æ–±—Ä–∞–Ω–æ –Ω–æ–≤–æ—Å—Ç–µ–π)
            query_raw = text("""
                SELECT
                    source_name,
                    COUNT(*) as total_collected
                FROM raw_articles
                WHERE fetched_at >= :date_from
                GROUP BY source_name
                ORDER BY total_collected DESC
            """)
            result_raw = await self.db.execute(query_raw, {"date_from": date_from})

            sources_collected = {}
            for row in result_raw.fetchall():
                sources_collected[row.source_name] = row.total_collected

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–º –ø–æ—Å—Ç–∞–º
            query_pubs = text("""
                SELECT
                    a.source_name,
                    COUNT(*) as total_published,
                    AVG(
                        (
                            COALESCE((p.reactions->>'useful')::int, 0) +
                            COALESCE((p.reactions->>'important')::int, 0) -
                            COALESCE((p.reactions->>'banal')::int, 0) -
                            COALESCE((p.reactions->>'obvious')::int, 0) -
                            COALESCE((p.reactions->>'poor_quality')::int, 0)
                        )::float / NULLIF(
                            COALESCE((p.reactions->>'useful')::int, 0) +
                            COALESCE((p.reactions->>'important')::int, 0) +
                            COALESCE((p.reactions->>'banal')::int, 0) +
                            COALESCE((p.reactions->>'obvious')::int, 0) +
                            COALESCE((p.reactions->>'poor_quality')::int, 0) +
                            COALESCE((p.reactions->>'controversial')::int, 0),
                            0
                        )
                    ) as avg_quality_score
                FROM publications p
                JOIN post_drafts d ON p.draft_id = d.id
                JOIN raw_articles a ON d.article_id = a.id
                WHERE p.published_at >= :date_from
                GROUP BY a.source_name
            """)
            result_pubs = await self.db.execute(query_pubs, {"date_from": date_from})

            sources = []
            for row in result_pubs.fetchall():
                source_name = row.source_name
                total_collected = sources_collected.get(source_name, 0)
                total_published = row.total_published or 0

                sources.append({
                    "source_name": source_name,
                    "total_collected": total_collected,
                    "total_published": total_published,
                    "publication_rate": (total_published / total_collected * 100) if total_collected > 0 else 0,
                    "avg_quality_score": round(row.avg_quality_score or 0, 2)
                })

            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
            sources.sort(key=lambda x: x["avg_quality_score"], reverse=True)

            return sources

        except Exception as e:
            logger.error("get_source_stats_error", error=str(e), days=days)
            return []

    async def get_weekday_stats(self, days: int = 30) -> Dict:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏.

        Args:
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–º–∏–Ω–∏–º—É–º 7)

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏
        """
        try:
            date_from = datetime.utcnow() - timedelta(days=days)

            query = text("""
                SELECT
                    EXTRACT(DOW FROM published_at) as day_of_week,
                    COUNT(*) as total_posts,
                    AVG(
                        (
                            COALESCE((reactions->>'useful')::int, 0) +
                            COALESCE((reactions->>'important')::int, 0) -
                            COALESCE((reactions->>'banal')::int, 0) -
                            COALESCE((reactions->>'obvious')::int, 0) -
                            COALESCE((reactions->>'poor_quality')::int, 0)
                        )::float / NULLIF(
                            COALESCE((reactions->>'useful')::int, 0) +
                            COALESCE((reactions->>'important')::int, 0) +
                            COALESCE((reactions->>'banal')::int, 0) +
                            COALESCE((reactions->>'obvious')::int, 0) +
                            COALESCE((reactions->>'poor_quality')::int, 0) +
                            COALESCE((reactions->>'controversial')::int, 0),
                            0
                        )
                    ) as avg_quality_score
                FROM publications
                WHERE published_at >= :date_from
                GROUP BY day_of_week
                ORDER BY day_of_week
            """)

            result = await self.db.execute(query, {"date_from": date_from})

            # –ú–∞–ø–ø–∏–Ω–≥ –¥–Ω–µ–π –Ω–µ–¥–µ–ª–∏ (0=–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ, 1=–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫, ...)
            day_names = {
                0: "–í—Å",
                1: "–ü–Ω",
                2: "–í—Ç",
                3: "–°—Ä",
                4: "–ß—Ç",
                5: "–ü—Ç",
                6: "–°–±"
            }

            weekday_stats = {}
            for row in result.fetchall():
                day_num = int(row.day_of_week)
                day_name = day_names.get(day_num, "??")

                weekday_stats[day_name] = {
                    "total_posts": row.total_posts or 0,
                    "avg_quality_score": round(row.avg_quality_score or 0, 2)
                }

            return weekday_stats

        except Exception as e:
            logger.error("get_weekday_stats_error", error=str(e), days=days)
            return {}

    async def get_vector_db_stats(self) -> Optional[Dict]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã Qdrant.

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ Qdrant –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
        """
        try:
            from app.modules.vector_search import get_vector_search
            from app.config import settings

            if not getattr(settings, "qdrant_enabled", False):
                return None

            vector_search = get_vector_search()

            # –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
            collection_info = vector_search.client.get_collection(
                collection_name=vector_search.COLLECTION_NAME
            )

            total_vectors = collection_info.points_count

            # –ü–æ–¥—Å—á–∏—Ç–∞—Ç—å –≤–µ–∫—Ç–æ—Ä—ã —Å —Ä–∞–∑–Ω—ã–º–∏ quality_score
            # Scroll —á–µ—Ä–µ–∑ –≤—Å–µ —Ç–æ—á–∫–∏ –∏ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞—Ç—å
            positive_count = 0
            negative_count = 0
            neutral_count = 0
            total_score = 0.0

            offset = None
            while True:
                results, next_offset = vector_search.client.scroll(
                    collection_name=vector_search.COLLECTION_NAME,
                    limit=100,
                    offset=offset,
                    with_payload=True,
                    with_vectors=False
                )

                if not results:
                    break

                for point in results:
                    quality_score = point.payload.get("quality_score", 0.0)
                    total_score += quality_score

                    if quality_score > 0.5:
                        positive_count += 1
                    elif quality_score < -0.3:
                        negative_count += 1
                    else:
                        neutral_count += 1

                offset = next_offset
                if offset is None:
                    break

            avg_score = (total_score / total_vectors) if total_vectors > 0 else 0.0

            return {
                "total_vectors": total_vectors,
                "positive_examples": positive_count,
                "negative_examples": negative_count,
                "neutral_examples": neutral_count,
                "avg_quality_score": round(avg_score, 2)
            }

        except Exception as e:
            logger.error("get_vector_db_stats_error", error=str(e))
            return None

    async def get_source_recommendations(self, days: int = 30) -> List[Dict]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º (–∫–∞–∫–∏–µ —Å—Ç–æ–∏—Ç –æ—Ç–∫–ª—é—á–∏—Ç—å).

        Args:
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –°–ø–∏—Å–æ–∫ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
        """
        try:
            date_from = datetime.utcnow() - timedelta(days=days)

            # –ù–∞—Ö–æ–¥–∏–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Å –Ω–∏–∑–∫–∏–º –∫–∞—á–µ—Å—Ç–≤–æ–º
            query = text("""
                SELECT
                    ra.source_name,
                    COUNT(p.id) as total_publications,
                    AVG(
                        (
                            COALESCE((p.reactions->>'useful')::int, 0) +
                            COALESCE((p.reactions->>'important')::int, 0) -
                            COALESCE((p.reactions->>'banal')::int, 0) -
                            COALESCE((p.reactions->>'obvious')::int, 0) -
                            COALESCE((p.reactions->>'poor_quality')::int, 0) -
                            COALESCE((p.reactions->>'low_content_quality')::int, 0) -
                            COALESCE((p.reactions->>'bad_source')::int, 0)
                        )::float / NULLIF(
                            COALESCE((p.reactions->>'useful')::int, 0) +
                            COALESCE((p.reactions->>'important')::int, 0) +
                            COALESCE((p.reactions->>'banal')::int, 0) +
                            COALESCE((p.reactions->>'obvious')::int, 0) +
                            COALESCE((p.reactions->>'poor_quality')::int, 0) +
                            COALESCE((p.reactions->>'low_content_quality')::int, 0) +
                            COALESCE((p.reactions->>'bad_source')::int, 0) +
                            COALESCE((p.reactions->>'controversial')::int, 0),
                            0
                        )
                    ) as avg_quality_score,
                    SUM(COALESCE((p.reactions->>'bad_source')::int, 0)) as bad_source_reactions,
                    SUM(COALESCE((p.reactions->>'low_content_quality')::int, 0)) as low_quality_reactions
                FROM publications p
                JOIN post_drafts pd ON p.draft_id = pd.id
                JOIN raw_articles ra ON pd.article_id = ra.id
                WHERE p.published_at >= :date_from
                GROUP BY ra.source_name
                HAVING COUNT(p.id) >= 2
            """)

            result = await self.db.execute(query, {"date_from": date_from})

            recommendations = []
            for row in result.fetchall():
                avg_score = row.avg_quality_score or 0.0
                bad_source_count = row.bad_source_reactions or 0
                low_quality_count = row.low_quality_reactions or 0
                total_pubs = row.total_publications

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é
                recommendation = None
                severity = None

                if avg_score < -0.4 and bad_source_count >= 2:
                    recommendation = "üö´ –û–¢–ö–õ–Æ–ß–ò–¢–¨: –ù–µ–Ω–∞–¥–µ–∂–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ —Å –Ω–∏–∑–∫–∏–º –∫–∞—á–µ—Å—Ç–≤–æ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"
                    severity = "critical"
                elif avg_score < -0.3 and (bad_source_count >= 1 or low_quality_count >= 2):
                    recommendation = "‚ö†Ô∏è –ü–†–û–í–ï–†–ò–¢–¨: –ò—Å—Ç–æ—á–Ω–∏–∫ —Å –ø—Ä–æ–±–ª–µ–º–∞–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞"
                    severity = "warning"
                elif avg_score < 0.0 and total_pubs >= 5:
                    recommendation = "üí° –ü–ï–†–ï–°–ú–û–¢–†–ï–¢–¨: –ò—Å—Ç–æ—á–Ω–∏–∫ —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º–∏ —Ä–µ–∞–∫—Ü–∏—è–º–∏"
                    severity = "info"

                if recommendation:
                    recommendations.append({
                        "source_name": row.source_name,
                        "total_publications": total_pubs,
                        "avg_quality_score": round(avg_score, 2),
                        "bad_source_reactions": bad_source_count,
                        "low_quality_reactions": low_quality_count,
                        "recommendation": recommendation,
                        "severity": severity
                    })

            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç–∏ (critical > warning > info)
            severity_order = {"critical": 0, "warning": 1, "info": 2}
            recommendations.sort(key=lambda x: (severity_order.get(x["severity"], 999), x["avg_quality_score"]))

            return recommendations

        except Exception as e:
            logger.error("get_source_recommendations_error", error=str(e), days=days)
            return []

    async def get_best_publish_time(self, days: int = 30) -> Dict:
        """
        –ê–Ω–∞–ª–∏–∑: –≤ –∫–∞–∫–æ–µ –≤—Ä–µ–º—è —Å—É—Ç–æ–∫ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –ø–æ–ª—É—á–∞—é—Ç –±–æ–ª—å—à–µ –≤—Å–µ–≥–æ engagement.
        A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏.

        Args:
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
        """
        try:
            date_from = datetime.utcnow() - timedelta(days=days)

            query = text("""
                SELECT
                    EXTRACT(HOUR FROM published_at) as hour_of_day,
                    COUNT(*) as total_posts,
                    AVG(views) as avg_views,
                    AVG(forwards) as avg_forwards,
                    AVG(
                        COALESCE((reactions->>'useful')::int, 0) +
                        COALESCE((reactions->>'important')::int, 0) +
                        COALESCE((reactions->>'controversial')::int, 0)
                    ) as avg_positive_reactions,
                    AVG(
                        (
                            COALESCE((reactions->>'useful')::int, 0) +
                            COALESCE((reactions->>'important')::int, 0) +
                            COALESCE((reactions->>'controversial')::int, 0)
                        )::float / NULLIF(views, 0)
                    ) as engagement_rate
                FROM publications
                WHERE published_at >= :date_from
                AND views > 0
                GROUP BY hour_of_day
                ORDER BY engagement_rate DESC
            """)

            result = await self.db.execute(query, {"date_from": date_from})

            hours_stats = []
            best_hour = None
            best_engagement = 0

            for row in result.fetchall():
                hour = int(row.hour_of_day)
                engagement_rate = row.engagement_rate or 0

                hours_stats.append({
                    "hour": hour,
                    "total_posts": row.total_posts,
                    "avg_views": round(row.avg_views or 0, 1),
                    "avg_forwards": round(row.avg_forwards or 0, 1),
                    "avg_positive_reactions": round(row.avg_positive_reactions or 0, 1),
                    "engagement_rate": round(engagement_rate * 100, 2)  # –í –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
                })

                if engagement_rate > best_engagement:
                    best_engagement = engagement_rate
                    best_hour = hour

            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é
            if best_hour is not None:
                recommendation = f"–õ—É—á—à–µ–µ –≤—Ä–µ–º—è –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: {best_hour:02d}:00-{(best_hour+1):02d}:00 MSK"
            else:
                recommendation = "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"

            return {
                "best_hour": best_hour,
                "best_engagement_rate": round(best_engagement * 100, 2) if best_engagement else 0,
                "recommendation": recommendation,
                "hours_stats": hours_stats
            }

        except Exception as e:
            logger.error("get_best_publish_time_error", error=str(e), days=days)
            return {
                "best_hour": None,
                "best_engagement_rate": 0,
                "recommendation": "–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞",
                "hours_stats": []
            }

    async def get_trending_topics(self, days: int = 7, top_n: int = 10) -> List[Dict]:
        """
        –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤—ã—Ö —Ç–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–æ–ø–æ–≤—ã—Ö –ø–æ—Å—Ç–æ–≤.
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —á–∞—Å—Ç–æ —É–ø–æ–º–∏–Ω–∞–µ–º—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤.

        Args:
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            top_n: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø-—Ç–µ–º –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞

        Returns:
            –°–ø–∏—Å–æ–∫ —Ç–µ–º —Å —á–∞—Å—Ç–æ—Ç–æ–π —É–ø–æ–º–∏–Ω–∞–Ω–∏–π
        """
        try:
            date_from = datetime.utcnow() - timedelta(days=days)

            # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø–æ–≤—ã–µ –ø–æ—Å—Ç—ã –∑–∞ –ø–µ—Ä–∏–æ–¥
            query = text("""
                SELECT
                    d.title,
                    d.content,
                    p.views,
                    (
                        COALESCE((p.reactions->>'useful')::int, 0) +
                        COALESCE((p.reactions->>'important')::int, 0)
                    ) as positive_reactions
                FROM publications p
                JOIN post_drafts d ON p.draft_id = d.id
                WHERE p.published_at >= :date_from
                AND p.views > 0
                ORDER BY positive_reactions DESC, p.views DESC
                LIMIT 30
            """)

            result = await self.db.execute(query, {"date_from": date_from})
            posts = result.fetchall()

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
            from collections import Counter
            import re

            # –°—Ç–æ–ø-—Å–ª–æ–≤–∞ (—Ä—É—Å—Å–∫–∏–µ)
            stop_words = {
                "–≤", "–∏", "–Ω–∞", "—Å", "–ø–æ", "–¥–ª—è", "–æ", "–æ—Ç", "–∫", "—É", "–∏–∑", "–∑–∞", "–Ω–∞–¥",
                "–ø–æ–¥", "–ø—Ä–∏", "—á—Ç–æ", "–∫–∞–∫", "—ç—Ç–æ", "–≤–µ—Å—å", "—Å–≤–æ–π", "–≤—Å–µ", "–º–æ–π", "–Ω–∞—à", "–≤–∞—à",
                "–∏—Ö", "–µ–≥–æ", "–µ—ë", "—ç—Ç–æ—Ç", "—Ç–æ—Ç", "–±—ã–ª", "–±—ã—Ç—å", "–µ—Å—Ç—å", "–Ω–µ—Ç", "–Ω–µ", "–Ω–∏",
                "—á–µ–º", "–≥–¥–µ", "–∫—É–¥–∞", "–∫–æ–≥–¥–∞", "–ø–æ—á–µ–º—É", "–∏–ª–∏", "–Ω–æ", "–∞", "–¥–∞"
            }

            words = []
            for post in posts:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ª–æ–≤–∞ –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞ (min 4 —Å–∏–º–≤–æ–ª–∞)
                title_words = re.findall(r'\b[–∞-—è—ë–ê-–Ø–Åa-zA-Z]{4,}\b', post.title.lower())
                words.extend([w for w in title_words if w not in stop_words])

            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —á–∞—Å—Ç–æ—Ç—É
            word_counts = Counter(words)
            trending = []

            for word, count in word_counts.most_common(top_n):
                trending.append({
                    "topic": word.capitalize(),
                    "mentions": count,
                    "relevance_score": round(count / len(posts) * 100, 1) if posts else 0
                })

            return trending

        except Exception as e:
            logger.error("get_trending_topics_error", error=str(e), days=days)
            return []

    async def get_performance_alerts(self, days: int = 7) -> List[Dict]:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–µ—Ç—Ä–∏–∫ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–ª–µ—Ä—Ç–æ–≤ –æ –ø—Ä–æ–±–ª–µ–º–∞—Ö.

        Args:
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –°–ø–∏—Å–æ–∫ –∞–ª–µ—Ä—Ç–æ–≤ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –ø—Ä–æ–±–ª–µ–º
        """
        try:
            alerts = []

            # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞: Engagement rate —É–ø–∞–ª > 20%
            stats_current = await self.get_period_stats(days)
            stats_previous = await self.get_period_stats(days * 2)  # –ü—Ä–µ–¥—ã–¥—É—â–∏–π –ø–µ—Ä–∏–æ–¥

            if stats_previous['engagement_rate'] > 0:
                engagement_drop = (
                    (stats_previous['engagement_rate'] - stats_current['engagement_rate']) /
                    stats_previous['engagement_rate'] * 100
                )

                if engagement_drop > 20:
                    alerts.append({
                        "severity": "warning",
                        "type": "engagement_drop",
                        "message": f"‚ö†Ô∏è Engagement rate —É–ø–∞–ª –Ω–∞ {engagement_drop:.1f}% –∑–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–¥–µ–ª—é",
                        "details": f"–ë—ã–ª–æ: {stats_previous['engagement_rate']:.1f}%, –°–µ–π—á–∞—Å: {stats_current['engagement_rate']:.1f}%"
                    })

            # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞: –ò—Å—Ç–æ—á–Ω–∏–∫–∏ —Å –ø–ª–æ—Ö–∏–º –∫–∞—á–µ—Å—Ç–≤–æ–º
            bad_sources = await self.get_source_recommendations(days)
            critical_sources = [s for s in bad_sources if s.get("severity") == "critical"]

            if critical_sources:
                source_names = ", ".join([s["source_name"] for s in critical_sources[:3]])
                alerts.append({
                    "severity": "critical",
                    "type": "bad_sources",
                    "message": f"üö´ –ù–∞–π–¥–µ–Ω—ã –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–º –∫–∞—á–µ—Å—Ç–≤–æ–º",
                    "details": f"–ò—Å—Ç–æ—á–Ω–∏–∫–∏: {source_names}"
                })

            # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞: –ù–∏–∑–∫–∏–π approval rate
            if stats_current['approval_rate'] < 50:
                alerts.append({
                    "severity": "info",
                    "type": "low_approval",
                    "message": f"üí° –ù–∏–∑–∫–∏–π approval rate: {stats_current['approval_rate']:.1f}%",
                    "details": f"–û–¥–æ–±—Ä–µ–Ω–æ {stats_current['approved_drafts']} –∏–∑ {stats_current['total_drafts']} –¥—Ä–∞—Ñ—Ç–æ–≤"
                })

            # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞: –ù–µ—Ç –ø—É–±–ª–∏–∫–∞—Ü–∏–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –¥–Ω—è
            if stats_current['total_publications'] == 0 and days >= 3:
                alerts.append({
                    "severity": "critical",
                    "type": "no_publications",
                    "message": "üö´ –ù–µ—Ç –ø—É–±–ª–∏–∫–∞—Ü–∏–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–Ω–∏",
                    "details": "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–±–æ—Ç—É –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ workflow"
                })

            return alerts

        except Exception as e:
            logger.error("get_performance_alerts_error", error=str(e), days=days)
            return []

    async def get_views_and_forwards_stats(self, days: int = 7) -> Dict:
        """
        –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ views –∏ forwards (–¥–æ—Å—Ç—É–ø–Ω–æ –ø–æ—Å–ª–µ —Å–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫ –∏–∑ Telegram).

        Args:
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π views/forwards
        """
        try:
            date_from = datetime.utcnow() - timedelta(days=days)

            query = text("""
                SELECT
                    COUNT(*) as total_posts,
                    SUM(views) as total_views,
                    SUM(forwards) as total_forwards,
                    AVG(views) as avg_views,
                    AVG(forwards) as avg_forwards,
                    MAX(views) as max_views,
                    MAX(forwards) as max_forwards
                FROM publications
                WHERE published_at >= :date_from
                AND views > 0
            """)

            result = await self.db.execute(query, {"date_from": date_from})
            row = result.fetchone()

            if row and row.total_posts > 0:
                return {
                    "total_posts": row.total_posts,
                    "total_views": row.total_views or 0,
                    "total_forwards": row.total_forwards or 0,
                    "avg_views": round(row.avg_views or 0, 1),
                    "avg_forwards": round(row.avg_forwards or 0, 1),
                    "max_views": row.max_views or 0,
                    "max_forwards": row.max_forwards or 0,
                    "viral_coefficient": round((row.total_forwards or 0) / (row.total_views or 1) * 100, 2)  # % –ø–æ—Å—Ç–æ–≤ –∫–æ—Ç–æ—Ä—ã–µ —Ñ–æ—Ä–≤–∞—Ä–¥—è—Ç
                }
            else:
                return {
                    "total_posts": 0,
                    "total_views": 0,
                    "total_forwards": 0,
                    "avg_views": 0,
                    "avg_forwards": 0,
                    "max_views": 0,
                    "max_forwards": 0,
                    "viral_coefficient": 0
                }

        except Exception as e:
            logger.error("get_views_and_forwards_stats_error", error=str(e), days=days)
            return {
                "total_posts": 0,
                "total_views": 0,
                "total_forwards": 0,
                "avg_views": 0,
                "avg_forwards": 0,
                "max_views": 0,
                "max_forwards": 0,
                "viral_coefficient": 0
            }

    async def get_ai_analysis_stats(self) -> Dict:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è AI –∞–Ω–∞–ª–∏–∑–∞ (—Ç–æ–∫–µ–Ω—ã –∏ —Å—Ç–æ–∏–º–æ—Å—Ç—å) —Å —Ä–∞–∑–±–∏–≤–∫–æ–π –ø–æ –º–æ–¥–µ–ª—è–º."""
        try:
            from datetime import date
            from dateutil.relativedelta import relativedelta

            today = date.today()
            month_start = date(today.year, today.month, 1)
            year_start = date(today.year, 1, 1)

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ —Ç–µ–∫—É—â–∏–π –º–µ—Å—è—Ü
            query_month = text("""
                SELECT
                    COUNT(*) as count,
                    SUM(total_tokens) as total_tokens,
                    SUM(cost_usd) as total_cost
                FROM api_usage
                WHERE operation = 'ai_analysis'
                AND date >= :month_start
            """)

            result_month = await self.db.execute(query_month, {"month_start": month_start})
            row_month = result_month.fetchone()

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ —Ç–µ–∫—É—â–∏–π –≥–æ–¥
            query_year = text("""
                SELECT
                    COUNT(*) as count,
                    SUM(total_tokens) as total_tokens,
                    SUM(cost_usd) as total_cost
                FROM api_usage
                WHERE operation = 'ai_analysis'
                AND date >= :year_start
            """)

            result_year = await self.db.execute(query_year, {"year_start": year_start})
            row_year = result_year.fetchone()

            # –†–∞–∑–±–∏–≤–∫–∞ –ø–æ –º–æ–¥–µ–ª—è–º –∑–∞ –º–µ—Å—è—Ü
            query_month_by_model = text("""
                SELECT
                    model,
                    COUNT(*) as count,
                    SUM(total_tokens) as total_tokens,
                    SUM(cost_usd) as total_cost
                FROM api_usage
                WHERE operation = 'ai_analysis'
                AND date >= :month_start
                GROUP BY model
            """)

            result_month_by_model = await self.db.execute(query_month_by_model, {"month_start": month_start})
            by_model_month = {}
            for row in result_month_by_model.fetchall():
                by_model_month[row.model] = {
                    "count": row.count,
                    "tokens": row.total_tokens or 0,
                    "cost_usd": float(row.total_cost or 0)
                }

            # –†–∞–∑–±–∏–≤–∫–∞ –ø–æ –º–æ–¥–µ–ª—è–º –∑–∞ –≥–æ–¥
            query_year_by_model = text("""
                SELECT
                    model,
                    COUNT(*) as count,
                    SUM(total_tokens) as total_tokens,
                    SUM(cost_usd) as total_cost
                FROM api_usage
                WHERE operation = 'ai_analysis'
                AND date >= :year_start
                GROUP BY model
            """)

            result_year_by_model = await self.db.execute(query_year_by_model, {"year_start": year_start})
            by_model_year = {}
            for row in result_year_by_model.fetchall():
                by_model_year[row.model] = {
                    "count": row.count,
                    "tokens": row.total_tokens or 0,
                    "cost_usd": float(row.total_cost or 0)
                }

            return {
                "month": {
                    "count": row_month.count or 0,
                    "total_tokens": row_month.total_tokens or 0,
                    "total_cost_usd": float(row_month.total_cost or 0),
                    "by_model": by_model_month
                },
                "year": {
                    "count": row_year.count or 0,
                    "total_tokens": row_year.total_tokens or 0,
                    "total_cost_usd": float(row_year.total_cost or 0),
                    "by_model": by_model_year
                }
            }

        except Exception as e:
            logger.error("get_ai_analysis_stats_error", error=str(e))
            return {
                "month": {"count": 0, "total_tokens": 0, "total_cost_usd": 0, "by_model": {}},
                "year": {"count": 0, "total_tokens": 0, "total_cost_usd": 0, "by_model": {}}
            }
